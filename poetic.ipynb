{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KpZqHw6RqjR-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense , Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "yihlifr7rDMJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filePath ,'rb').read().decode(encoding='utf-8').lower()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wquH60dnr_G7",
        "outputId": "8163381b-e13f-427d-eeb0-8a310045da6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text[300000:800000]\n",
        "characters = sorted(set(text))\n",
        "char_to_index = dict((c,i) for i,c  in enumerate(characters))\n",
        "index_to_char = dict((i,c) for i,c  in enumerate(characters))"
      ],
      "metadata": {
        "id": "zoMkdUeQtu4e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 40\n",
        "step_size = 3\n",
        "sentences = []\n",
        "next_characters =[]\n",
        "\n",
        "for i  in range(0 , len(text)-seq_length,step_size):\n",
        "  sentences.append(text[i:i+seq_length])\n",
        "  next_characters.append(text[i+seq_length])"
      ],
      "metadata": {
        "id": "vm8pibEgu-BF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), seq_length,\n",
        "              len(characters)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=np.bool)\n",
        "\n",
        "for i,sentence in enumerate(sentences):\n",
        "  for t,character in enumerate(sentence) :\n",
        "    x[i,t,char_to_index[character]]=1\n",
        "  y[i,char_to_index[next_characters[i]]]=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViJ0FWdZd0UQ",
        "outputId": "529e9fd5-4de6-43fd-90a9-ea1ca89ce065"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f868b05adf80>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  len(characters)), dtype=np.bool)\n",
            "<ipython-input-11-f868b05adf80>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  len(characters)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  model = Sequential()\n",
        "  model.add(LSTM(128,input_shape=(seq_length, len(characters))))\n",
        "  model.add(Dense(len(characters)))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=RMSprop(learning_rate=0.01))\n",
        "  model.fit(x,y,batch_size=256,epochs=4)\n",
        "  model.save('textgenerator.model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7EMAofuoH0z",
        "outputId": "6e4f2e78-d184-4e1b-cc60-1c7cbe130529"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 128s 193ms/step - loss: 2.1584\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 130s 200ms/step - loss: 1.7281\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 124s 191ms/step - loss: 1.6018\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 124s 190ms/step - loss: 1.5309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('textgenerator.model')\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "kbxzAGNhtJwl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length,temperture):\n",
        "  start_index = random.randint(0,len(text)-seq_length -1)\n",
        "  generated = ''\n",
        "  sentence = text[start_index:start_index + seq_length]\n",
        "  generated += sentence\n",
        "  for i in range(length):\n",
        "    x = np.zeros((1,seq_length,len(characters)))\n",
        "    for t,character in enumerate(sentence):\n",
        "      x[0,t,char_to_index[character]]=1\n",
        "    predictions = model.predict(x,verbose=0)[0]\n",
        "    next_index = sample(predictions , temperture)\n",
        "    next_character = index_to_char[next_index]\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:]+next_character\n",
        "  return generated"
      ],
      "metadata": {
        "id": "uBB1Wf0nthFO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('_________________________0.2______')\n",
        "print(generate_text(300, 0.2))\n",
        "print('_________________________0.4______')\n",
        "print(generate_text(300, 0.4))\n",
        "print('_________________________0.5______')\n",
        "print(generate_text(300, 0.5))\n",
        "print('_________________________0.6______')\n",
        "print(generate_text(300, 0.6))\n",
        "print('_________________________0.7______')\n",
        "print(generate_text(300, 0.7))\n",
        "print('_________________________0.8______')\n",
        "print(generate_text(300, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Bj9ZAIyxJb",
        "outputId": "cc7599b1-75d5-48dd-ca48-ff0069f18c7e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________________0.2______\n",
            "igh, my lord?\n",
            "\n",
            "king henry vi:\n",
            "not for my lord, and i will strengther son.\n",
            "\n",
            "romeo:\n",
            "and the regense the seaver to the bears,\n",
            "and i see is the bears, with the recouss\n",
            "and in the romeo, the father and the words,\n",
            "and i will i see the seaver to the father,\n",
            "and i see to the counting to the breath,\n",
            "and i see to mer to the father with the cause\n",
            "to\n",
            "_________________________0.4______\n",
            "d by the way\n",
            "and lost all my money?\n",
            "\n",
            "autolycus:\n",
            "why, so shall stret shall see but of the bastress\n",
            "on the strung to the redoth of the black.\n",
            "\n",
            "romeo:\n",
            "and i confess in the baster of these is the rear.\n",
            "\n",
            "clown:\n",
            "we was the world, i have say for the heaven,\n",
            "as when i streaked to be to my bearty to the cause,\n",
            "to my lord, to may thou streaked to t\n",
            "_________________________0.5______\n",
            "rrish riddles sort not with this place.\n",
            "\n",
            "romeo:\n",
            "now i see the repuse to the grave sire every speak.\n",
            "\n",
            "semplo:\n",
            "a duke of arms? god such such this stands true heart and all all thine heart shall i thereon,\n",
            "to thy brother many truth: hereford, for all therefore,\n",
            "to see were that i heart a daughter, to be there\n",
            "to prace of my hope of the bonge\n",
            "_________________________0.6______\n",
            "he foil\n",
            "of england's chair, where he is the gair,\n",
            "and to the earth of who canst down burbol,\n",
            "in the cause to him to do it i would that be to me\n",
            "to so much as i to be the victing to the father,\n",
            "to the bedight the forth the carmand no mind of but.\n",
            "\n",
            "romeo:\n",
            "i capure with the holds you hath to the basener,\n",
            "to she true go to be before is the bi\n",
            "_________________________0.7______\n",
            "he\n",
            "hai!\n",
            "\n",
            "benvolio:\n",
            "the what?\n",
            "\n",
            "mercutio:\n",
            "hath it a poosily boy, or our sare was up the read?\n",
            "why, it i do to you bear tite them read ampainted,\n",
            "and altty know your lord, but i am but see his son\n",
            "you have boy of the cause to have i am defend;\n",
            "now stren god ben my drupkery he, so many\n",
            "sirner: the but with the right see i shall in their happ \n",
            "_________________________0.8______\n",
            "better burn it now\n",
            "than curse it then. but i were not the sean\n",
            "so again, to bleaten free but becion it,\n",
            "and you have not with thise mastard, obedem\n",
            "here as 'capulet, with somers o'er king.\n",
            "\n",
            "romeo:\n",
            "sir is the blother be received warwick,\n",
            "and, how i preserved with to the such sir.\n",
            "\n",
            "king richard iiin:\n",
            "upot the freit dost to feed, you behort\n",
            "\n"
          ]
        }
      ]
    }
  ]
}